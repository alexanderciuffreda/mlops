{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "penguin_simple.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DjUA6S30k52h"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "dbd8eb4d6d44a9ee498831c173af7cb004b4474f7e38478603cc08ebccd5e9de"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('tfx-env': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexanderciuffreda/mlops/blob/main/tfx/notebooks/pipeline-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjUA6S30k52h"
      },
      "source": [
        "# Simple TFX Pipeline Tutorial using Penguin dataset\n",
        "\n",
        "*This tutorial is based on an example from\n",
        "the [Tensor Flow documentation](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple)*\n",
        "\n",
        "In this notebook-based tutorial, we will create and run a TFX pipeline\n",
        "for a simple classification model.\n",
        "\n",
        "The pipeline will consist of three essential TFX components:\n",
        "\n",
        "- ExampleGen,\n",
        "- Trainer and\n",
        "- Pusher.\n",
        "\n",
        "The pipeline includes the most minimal ML workflow like\n",
        "\n",
        "- importing data,\n",
        "- training a model and\n",
        "- exporting the trained model.\n",
        "\n",
        "Please see\n",
        "[Understanding TFX Pipelines](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines)\n",
        "to learn more about various concepts in TFX."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDnPgN8UJtzN"
      },
      "source": [
        "## TFX setup\n",
        "\n",
        "- Import Tensor Flow and TFX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8H2_GD9L3cU"
      },
      "source": [
        "!pip install -q -U tensorflow==2.6.0 tfx==1.3.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:41.801016Z",
          "iopub.status.busy": "2021-09-30T02:03:41.800485Z",
          "iopub.status.idle": "2021-09-30T02:03:46.696403Z",
          "shell.execute_reply": "2021-09-30T02:03:46.696798Z"
        },
        "id": "6jh7vKSRqPHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41e1db9-2e9d-4718-9e3e-44dedc993eab"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tfx import v1 as tfx\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.6.0\n",
            "TFX version: 1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDtLdSkvqPHe"
      },
      "source": [
        "## Set up variables\n",
        "\n",
        "- There are some variables used to define a pipeline.\n",
        "- You can customize these variables as you want.\n",
        "- By default, all output from the pipeline will be generated under the current directory.\n",
        "\n",
        "We use [ML Metadata (MLMD)](https://www.tensorflow.org/tfx/guide/mlmd) as a library for\n",
        "recording and retrieving metadata associated with our workflows.\n",
        "MLMD is an integral part of TensorFlow Extended (TFX),\n",
        "but is designed so that it can be used independently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:46.702139Z",
          "iopub.status.busy": "2021-09-30T02:03:46.701551Z",
          "iopub.status.idle": "2021-09-30T02:03:46.703204Z",
          "shell.execute_reply": "2021-09-30T02:03:46.703524Z"
        },
        "id": "EcUseqJaE2XN"
      },
      "source": [
        "import os\n",
        "\n",
        "PIPELINE_NAME = \"engine-simple\"\n",
        "\n",
        "# Output directory to store artifacts generated from the pipeline.\n",
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
        "# Path to a SQLite DB file to use as an MLMD storage.\n",
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
        "# Output directory where created models from the pipeline will be exported.\n",
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
        "\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.INFO)  # Set default logging level."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F2SRwRLSYGa"
      },
      "source": [
        "## Prepare example data\n",
        "\n",
        "We will download the engine dataset for use in our TFX pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11J7XiCq6AFP"
      },
      "source": [
        "Because TFX ExampleGen reads inputs from a directory, we need to create a\n",
        "directory and copy dataset to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:46.709239Z",
          "iopub.status.busy": "2021-09-30T02:03:46.708641Z",
          "iopub.status.idle": "2021-09-30T02:03:47.096264Z",
          "shell.execute_reply": "2021-09-30T02:03:47.096697Z"
        },
        "id": "4fxMs6u86acP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083dd9fc-bb82-487b-b060-68e6900c832b"
      },
      "source": [
        "import urllib.request\n",
        "import tempfile\n",
        "\n",
        "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
        "_data_url = 'https://github.com/alexanderciuffreda/mlops/raw/main/dataset/engine-train.csv'\n",
        "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
        "urllib.request.urlretrieve(_data_url, _data_filepath)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/tfx-dataeya7tcmb/data.csv', <http.client.HTTPMessage at 0x7f184197b390>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpoNmxKSQjI"
      },
      "source": [
        "Take a quick look at the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:47.106850Z",
          "iopub.status.busy": "2021-09-30T02:03:47.100446Z",
          "iopub.status.idle": "2021-09-30T02:03:47.221653Z",
          "shell.execute_reply": "2021-09-30T02:03:47.222037Z"
        },
        "id": "-eSz28UDSnlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ccbdf9-2385-42ad-ff49-aebdf319e0af"
      },
      "source": [
        "!head {_data_filepath}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",id,cycle,op1,op2,op3,sensor1,sensor2,sensor3,sensor4,sensor5,sensor6,sensor7,sensor8,sensor9,sensor10,sensor11,sensor12,sensor13,sensor14,sensor15,sensor16,sensor17,sensor18,sensor19,sensor20,sensor21,remaining_cycle,label\n",
            "0,1,1,-0.0007,-0.0004,100.0,518.67,641.82,1589.7,1400.6,14.62,21.61,554.36,2388.06,9046.19,1.3,47.47,521.66,2388.02,8138.62,8.4195,0.03,392,2388,100.0,39.06,23.419,191,0\n",
            "1,1,2,0.0019,-0.0003,100.0,518.67,642.15,1591.82,1403.14,14.62,21.61,553.75,2388.04,9044.07,1.3,47.49,522.28,2388.07,8131.49,8.4318,0.03,392,2388,100.0,39.0,23.4236,190,0\n",
            "2,1,3,-0.0043,0.0003,100.0,518.67,642.35,1587.99,1404.2,14.62,21.61,554.26,2388.08,9052.94,1.3,47.27,522.42,2388.03,8133.23,8.4178,0.03,390,2388,100.0,38.95,23.3442,189,0\n",
            "3,1,4,0.0007,0.0,100.0,518.67,642.35,1582.79,1401.87,14.62,21.61,554.45,2388.11,9049.48,1.3,47.13,522.86,2388.08,8133.83,8.3682,0.03,392,2388,100.0,38.88,23.3739,188,0\n",
            "4,1,5,-0.0019,-0.0002,100.0,518.67,642.37,1582.85,1406.22,14.62,21.61,554.0,2388.06,9055.15,1.3,47.28,522.19,2388.04,8133.8,8.4294,0.03,393,2388,100.0,38.9,23.4044,187,0\n",
            "5,1,6,-0.0043,-0.0001,100.0,518.67,642.1,1584.47,1398.37,14.62,21.61,554.67,2388.02,9049.68,1.3,47.16,521.68,2388.03,8132.85,8.4108,0.03,391,2388,100.0,38.98,23.3669,186,0\n",
            "6,1,7,0.001,0.0001,100.0,518.67,642.48,1592.32,1397.77,14.62,21.61,554.34,2388.02,9059.13,1.3,47.36,522.32,2388.03,8132.32,8.3974,0.03,392,2388,100.0,39.1,23.3774,185,0\n",
            "7,1,8,-0.0034,0.0003,100.0,518.67,642.56,1582.96,1400.97,14.62,21.61,553.85,2388.0,9040.8,1.3,47.24,522.47,2388.03,8131.07,8.4076,0.03,391,2388,100.0,38.97,23.3106,184,0\n",
            "8,1,9,0.0008,0.0001,100.0,518.67,642.12,1590.98,1394.8,14.62,21.61,553.69,2388.05,9046.46,1.3,47.29,521.79,2388.05,8125.69,8.3728,0.03,392,2388,100.0,39.05,23.4066,183,0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTtQNq1DdVvG"
      },
      "source": [
        "You should be able to see five values. `species` is one of 0, 1 or 2, and all\n",
        "other features should have values between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH6gizcpSwWV"
      },
      "source": [
        "## Create a pipeline\n",
        "\n",
        "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
        "consists of following three components.\n",
        "- CsvExampleGen: Reads in data files and convert them to TFX internal format\n",
        "for further processing. There are multiple\n",
        "[ExampleGen](https://www.tensorflow.org/tfx/guide/examplegen)s for various\n",
        "formats. In this tutorial, we will use CsvExampleGen which takes CSV file input.\n",
        "- Trainer: Trains an ML model.\n",
        "[Trainer component](https://www.tensorflow.org/tfx/guide/trainer) requires a\n",
        "model definition code from users. You can use TensorFlow APIs to specify how to\n",
        "train a model and save it in a _saved_model_ format.\n",
        "- Pusher: Copies the trained model outside of the TFX pipeline.\n",
        "[Pusher component](https://www.tensorflow.org/tfx/guide/pusher) can be thought\n",
        "of an deployment process of the trained ML model.\n",
        "\n",
        "Before actually define the pipeline, we need to write a model code for the\n",
        "Trainer component first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOjDv93eS5xV"
      },
      "source": [
        "### Write model training code\n",
        "\n",
        "We will create a simple DNN model for classification using TensorFlow Keras\n",
        "API. This model training code will be saved to a separate file.\n",
        "\n",
        "In this tutorial we will use\n",
        "[Generic Trainer](https://www.tensorflow.org/tfx/guide/trainer#generic_trainer)\n",
        "of TFX which support Keras-based models. You need to write a Python file\n",
        "containing `run_fn` function, which is the entrypoint for the `Trainer`\n",
        "component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:47.226822Z",
          "iopub.status.busy": "2021-09-30T02:03:47.226246Z",
          "iopub.status.idle": "2021-09-30T02:03:47.228225Z",
          "shell.execute_reply": "2021-09-30T02:03:47.227827Z"
        },
        "id": "aES7Hv5QTDK3"
      },
      "source": [
        "_trainer_module_file = 'engine_trainer.py'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:47.234274Z",
          "iopub.status.busy": "2021-09-30T02:03:47.233690Z",
          "iopub.status.idle": "2021-09-30T02:03:47.237014Z",
          "shell.execute_reply": "2021-09-30T02:03:47.236578Z"
        },
        "id": "Gnc67uQNTDfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66603b39-fb7c-4155-8b2a-624e52cf81f7"
      },
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx import v1 as tfx\n",
        "from tfx_bsl.public import tfxio\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "op_set = [\"op\"+str(i) for i in range(1,4)]\n",
        "sensor = [\"sensor\"+str(i) for i in range(1,22)]\n",
        "\n",
        "_FEATURE_KEYS = op_set + sensor\n",
        "_LABEL_KEY = 'label'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "# Since we're not generating or creating a schema, we will instead create\n",
        "# a feature spec.  Since there are a fairly small number of features this is\n",
        "# manageable for this dataset.\n",
        "_FEATURE_SPEC = {\n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
        "           for feature in _FEATURE_KEYS\n",
        "       },\n",
        "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[str],\n",
        "              data_accessor: tfx.components.DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    schema: schema of the input data.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      tfxio.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
        "      schema=schema).repeat()\n",
        "\n",
        "\n",
        "def _build_keras_model() -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model.\n",
        "  \"\"\"\n",
        "  # The model below is built with Functional API, please refer to\n",
        "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
        "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
        "  d = keras.layers.concatenate(inputs)\n",
        "  for _ in range(2):\n",
        "    d = keras.layers.Dense(8, activation='relu')(d)\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(1e-2),\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  model.summary(print_fn=logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: tfx.components.FnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "\n",
        "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
        "  # version provided by pipeline author. A schema can also derived from TFT\n",
        "  # graph if a Transform component is used. In the case when either is missing,\n",
        "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
        "  # feature_spec, but the schema returned would be very primitive.\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_TRAIN_BATCH_SIZE)\n",
        "  eval_dataset = _input_fn(\n",
        "      fn_args.eval_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size=_EVAL_BATCH_SIZE)\n",
        "\n",
        "  model = _build_keras_model()\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
        "  # directory.\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting engine_trainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaw0rs-emEf"
      },
      "source": [
        "Now you have completed all preparation steps to build a TFX pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OkNz3gTLwM"
      },
      "source": [
        "### Write a pipeline definition\n",
        "\n",
        "We define a function to create a TFX pipeline. A `Pipeline` object\n",
        "represents a TFX pipeline which can be run using one of pipeline\n",
        "orchestration systems that TFX supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:47.243569Z",
          "iopub.status.busy": "2021-09-30T02:03:47.242984Z",
          "iopub.status.idle": "2021-09-30T02:03:47.244895Z",
          "shell.execute_reply": "2021-09-30T02:03:47.244495Z"
        },
        "id": "M49yYVNBTPd4"
      },
      "source": [
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
        "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
        "  # Brings data into the pipeline.\n",
        "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
        "\n",
        "  # Uses user-provided Python function that trains a model.\n",
        "  trainer = tfx.components.Trainer(\n",
        "      module_file=module_file,\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=tfx.proto.TrainArgs(num_steps=100000),\n",
        "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
        "\n",
        "  # Pushes the model to a filesystem destination.\n",
        "  pusher = tfx.components.Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      push_destination=tfx.proto.PushDestination(\n",
        "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
        "              base_directory=serving_model_dir)))\n",
        "\n",
        "  # Following three components will be included in the pipeline.\n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return tfx.dsl.Pipeline(\n",
        "      pipeline_name=pipeline_name,\n",
        "      pipeline_root=pipeline_root,\n",
        "      metadata_connection_config=tfx.orchestration.metadata\n",
        "      .sqlite_metadata_connection_config(metadata_path),\n",
        "      components=components)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJbq07THU2GV"
      },
      "source": [
        "## Run the pipeline\n",
        "\n",
        "TFX supports multiple orchestrators to run pipelines.\n",
        "In this tutorial we will use `LocalDagRunner` which is included in the TFX\n",
        "Python package and runs pipelines on local environment.\n",
        "We often call TFX pipelines \"DAGs\" which stands for directed acyclic graph.\n",
        "\n",
        "`LocalDagRunner` provides fast iterations for developemnt and debugging.\n",
        "TFX also supports other orchestrators including Kubeflow Pipelines and Apache\n",
        "Airflow which are suitable for production use cases.\n",
        "\n",
        "See\n",
        "[TFX on Cloud AI Platform Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/cloud-ai-platform-pipelines)\n",
        "or\n",
        "[TFX Airflow Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/airflow_workshop)\n",
        "to learn more about other orchestration systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mp0AkmrPdUb"
      },
      "source": [
        "Now we create a `LocalDagRunner` and pass a `Pipeline` object created from the\n",
        "function we already defined.\n",
        "\n",
        "The pipeline runs directly and you can see logs for the progress of the pipeline including ML model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:47.252552Z",
          "iopub.status.busy": "2021-09-30T02:03:47.252019Z",
          "iopub.status.idle": "2021-09-30T02:03:54.024486Z",
          "shell.execute_reply": "2021-09-30T02:03:54.024855Z"
        },
        "id": "fAtfOZTYWJu-"
      },
      "source": [
        "tfx.orchestration.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name=PIPELINE_NAME,\n",
        "      pipeline_root=PIPELINE_ROOT,\n",
        "      data_root=DATA_ROOT,\n",
        "      module_file=_trainer_module_file,\n",
        "      serving_model_dir=SERVING_MODEL_DIR,\n",
        "      metadata_path=METADATA_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppERq0Mj6xvW"
      },
      "source": [
        "You should see \"INFO:absl:Component Pusher is finished.\" at the end of the\n",
        "logs if the pipeline finished successfully. Because `Pusher` component is the\n",
        "last component of the pipeline.\n",
        "\n",
        "The pusher component pushes the trained model to the `SERVING_MODEL_DIR` which\n",
        "is the `serving_model/penguin-simple` directory if you did not change the\n",
        "variables in the previous steps. You can see the result from the file browser\n",
        "in the left-side panel in Colab, or using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-30T02:03:54.045513Z",
          "iopub.status.busy": "2021-09-30T02:03:54.028847Z",
          "iopub.status.idle": "2021-09-30T02:03:54.172911Z",
          "shell.execute_reply": "2021-09-30T02:03:54.173296Z"
        },
        "id": "NTHROkqX6yHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f20b651-a14a-487e-fcac-1918258e1c18"
      },
      "source": [
        "# List files in created model directory.\n",
        "!find {SERVING_MODEL_DIR}"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "serving_model/engine-simple\n",
            "serving_model/engine-simple/1635721911\n",
            "serving_model/engine-simple/1635721911/saved_model.pb\n",
            "serving_model/engine-simple/1635721911/variables\n",
            "serving_model/engine-simple/1635721911/variables/variables.index\n",
            "serving_model/engine-simple/1635721911/variables/variables.data-00000-of-00001\n",
            "serving_model/engine-simple/1635721911/assets\n",
            "serving_model/engine-simple/1635721911/keras_metadata.pb\n",
            "serving_model/engine-simple/1635722224\n",
            "serving_model/engine-simple/1635722224/saved_model.pb\n",
            "serving_model/engine-simple/1635722224/variables\n",
            "serving_model/engine-simple/1635722224/variables/variables.index\n",
            "serving_model/engine-simple/1635722224/variables/variables.data-00000-of-00001\n",
            "serving_model/engine-simple/1635722224/assets\n",
            "serving_model/engine-simple/1635722224/keras_metadata.pb\n",
            "serving_model/engine-simple/1635721631\n",
            "serving_model/engine-simple/1635721631/saved_model.pb\n",
            "serving_model/engine-simple/1635721631/variables\n",
            "serving_model/engine-simple/1635721631/variables/variables.index\n",
            "serving_model/engine-simple/1635721631/variables/variables.data-00000-of-00001\n",
            "serving_model/engine-simple/1635721631/assets\n",
            "serving_model/engine-simple/1635721631/keras_metadata.pb\n",
            "serving_model/engine-simple/1635721977\n",
            "serving_model/engine-simple/1635721977/saved_model.pb\n",
            "serving_model/engine-simple/1635721977/variables\n",
            "serving_model/engine-simple/1635721977/variables/variables.index\n",
            "serving_model/engine-simple/1635721977/variables/variables.data-00000-of-00001\n",
            "serving_model/engine-simple/1635721977/assets\n",
            "serving_model/engine-simple/1635721977/keras_metadata.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hELdfipqhyc"
      },
      "source": [
        "model = tf.keras.models.load_model('model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08R8qvweThRf"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can find more resources on https://www.tensorflow.org/tfx/tutorials.\n",
        "\n",
        "Please see\n",
        "[Understanding TFX Pipelines](https://www.tensorflow.org/tfx/guide/understanding_tfx_pipelines)\n",
        "to learn more about various concepts in TFX.\n"
      ]
    }
  ]
}