{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from deltalake import DeltaTable\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/30 17:34:43 WARN Utils: Your hostname, MacBook-Air-von-Alexander.local resolves to a loopback address: 127.0.0.1; using 192.168.0.9 instead (on interface en0)\n",
      "22/01/30 17:34:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/alexander/miniforge3/envs/spark/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/alexander/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/alexander/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7944e5d6-9c09-446a-862d-50984786675f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;1.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      ":: resolution report :: resolve 287ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;1.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7944e5d6-9c09-446a-862d-50984786675f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/12ms)\n",
      "22/01/30 17:34:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/30 17:34:54 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create spark context\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"mlops\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "# read data\n",
    "df_test = spark.read.csv(\"/Users/alexander/mlops/dataset/test_FD001.txt\", sep=\" \")\n",
    "df_train = spark.read.csv(\"/Users/alexander/mlops/dataset/train_FD001.txt\", sep=\" \")\n",
    "df_rul = spark.read.csv(\"/Users/alexander/mlops/dataset/RUL_FD001.txt\", sep=\" \",)\n",
    "\n",
    "\n",
    "# save data in delta lake bronze stage\n",
    "df_test.write.format(\"delta\").save(\"delta-lake/bronze/test_data\")\n",
    "df_train.write.format(\"delta\").save(\"delta-lake/bronze/train_data\")\n",
    "df_rul.write.format(\"delta\").save(\"delta-lake/bronze/rul_data\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column names\n",
    "cols=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from deltalake\n",
    "dt_test = DeltaTable(\"delta-lake/bronze/test_data\")\n",
    "dt_train = DeltaTable(\"delta-lake/bronze/train_data\")\n",
    "dt_rul =  DeltaTable(\"delta-lake/bronze/rul_data\")\n",
    "\n",
    "# convert to dataframe\n",
    "test = dt_test.to_pandas()\n",
    "train = dt_train.to_pandas()\n",
    "test_results = dt_rul.to_pandas()\n",
    "\n",
    "# set column names\n",
    "test.columns = cols\n",
    "train.columns = cols\n",
    "\n",
    "# set datatypes\n",
    "test = test.apply(pd.to_numeric)\n",
    "train = train.apply(pd.to_numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate remaining cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train=pd.read_csv(\"train_FD001.txt\",sep=\" \",names=columns)\n",
    "#test=pd.read_csv(\"test_FD001.txt\",sep=\" \",names=columns)\n",
    "#test_results=pd.read_csv(\"RUL_FD001.txt\",sep=\" \",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate columns for RUL, cycle, rul failed, remaining cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_results.apply(pd.to_numeric)\n",
    "test_results.columns=[\"rul\", \"null\"]\n",
    "\n",
    "test_results['id']=test_results.index+1\n",
    "test_results.drop([\"null\"],axis=1,inplace=True)\n",
    "rul = pd.DataFrame(test.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "test_results['rul_failed']=test_results['rul']+rul['max']\n",
    "test_results.drop([\"rul\"],axis=1,inplace=True)\n",
    "test=test.merge(test_results,on=['id'],how='left')\n",
    "test[\"remaining_cycle\"]=test[\"rul_failed\"]-test[\"cycle\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop null values and rul failed for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=train.drop([\"sensor22\",\"sensor23\"],axis=1)\n",
    "df_test=test.drop([\"sensor22\",\"sensor23\"],axis=1)\n",
    "df_test.drop([\"rul_failed\"],axis=1,inplace=True)\n",
    "df_train['remaining_cycle'] = df_train.groupby(['id'])['cycle'].transform(max)-df_train['cycle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>op1</th>\n",
       "      <th>op2</th>\n",
       "      <th>op3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>sensor22</th>\n",
       "      <th>sensor23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle     op1     op2    op3  sensor1  sensor2  sensor3  sensor4  \\\n",
       "0   1      1 -0.0007 -0.0004  100.0   518.67   641.82  1589.70  1400.60   \n",
       "1   1      2  0.0019 -0.0003  100.0   518.67   642.15  1591.82  1403.14   \n",
       "2   1      3 -0.0043  0.0003  100.0   518.67   642.35  1587.99  1404.20   \n",
       "3   1      4  0.0007  0.0000  100.0   518.67   642.35  1582.79  1401.87   \n",
       "4   1      5 -0.0019 -0.0002  100.0   518.67   642.37  1582.85  1406.22   \n",
       "\n",
       "   sensor5  ...  sensor14  sensor15  sensor16  sensor17  sensor18  sensor19  \\\n",
       "0    14.62  ...   8138.62    8.4195      0.03       392      2388     100.0   \n",
       "1    14.62  ...   8131.49    8.4318      0.03       392      2388     100.0   \n",
       "2    14.62  ...   8133.23    8.4178      0.03       390      2388     100.0   \n",
       "3    14.62  ...   8133.83    8.3682      0.03       392      2388     100.0   \n",
       "4    14.62  ...   8133.80    8.4294      0.03       393      2388     100.0   \n",
       "\n",
       "   sensor20  sensor21  sensor22  sensor23  \n",
       "0     39.06   23.4190       NaN       NaN  \n",
       "1     39.00   23.4236       NaN       NaN  \n",
       "2     38.95   23.3442       NaN       NaN  \n",
       "3     38.88   23.3739       NaN       NaN  \n",
       "4     38.90   23.4044       NaN       NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set CYCLES variable to predict if the engine will fail within the next n cycles\n",
    "CYCLES = 20 # predict if the engine will fail in the next 20 cycles\n",
    "df_train['label'] = df_train['remaining_cycle'].apply(lambda x: 1 if x <= CYCLES else 0)\n",
    "df_test['label'] = df_test['remaining_cycle'].apply(lambda x: 1 if x <= CYCLES else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"sensor17\"] = pd.to_numeric(df_train[\"sensor17\"], downcast=\"float\")\n",
    "df_test[\"sensor17\"] = pd.to_numeric(df_test[\"sensor17\"], downcast=\"float\")\n",
    "df_train[\"sensor18\"] = pd.to_numeric(df_train[\"sensor18\"], downcast=\"float\")\n",
    "df_test[\"sensor18\"] = pd.to_numeric(df_test[\"sensor18\"], downcast=\"float\")\n",
    "df_train[\"sensor19\"] = pd.to_numeric(df_train[\"sensor19\"], downcast=\"float\")\n",
    "df_test[\"sensor19\"] = pd.to_numeric(df_test[\"sensor19\"], downcast=\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   int64\n",
       "cycle                int64\n",
       "op1                float64\n",
       "op2                float64\n",
       "op3                float64\n",
       "sensor1            float64\n",
       "sensor2            float64\n",
       "sensor3            float64\n",
       "sensor4            float64\n",
       "sensor5            float64\n",
       "sensor6            float64\n",
       "sensor7            float64\n",
       "sensor8            float64\n",
       "sensor9            float64\n",
       "sensor10           float64\n",
       "sensor11           float64\n",
       "sensor12           float64\n",
       "sensor13           float64\n",
       "sensor14           float64\n",
       "sensor15           float64\n",
       "sensor16           float64\n",
       "sensor17           float32\n",
       "sensor18           float32\n",
       "sensor19           float32\n",
       "sensor20           float64\n",
       "sensor21           float64\n",
       "remaining_cycle      int64\n",
       "label                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parquet\n",
    "#df_train.to_parquet('engine-train.parquet')\n",
    "#df_test.to_parquet('engine-test.parquet')\n",
    "\n",
    "#csv\n",
    "#df_train.to_csv('engine-train.csv')\n",
    "#df_test.to_csv('engine-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframes to spark dataframes\n",
    "df_test_silver = spark.createDataFrame(df_test)\n",
    "df_train_silver = spark.createDataFrame(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/30 18:13:32 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/01/30 18:13:32 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/01/30 18:13:33 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/01/30 18:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/01/30 18:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/01/30 18:13:37 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# save prepared data in delta lake silver stage\n",
    "df_test_silver.write.format(\"delta\").save(\"delta-lake/silver/test_data\")\n",
    "df_train_silver.write.format(\"delta\").save(\"delta-lake/silver/train_data\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93c60d43ab9c456a5156912bdf0fd87b359a69a79e1b2872312e808356bafea1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('airflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
